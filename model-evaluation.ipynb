{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# essentials\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading models and vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"models/word2vecs/pwc3-win7-vec100-min5/predicor-lr0.001-batch128.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/word2vecs/pwc3-win7-vec100-min5/vocabulary_small.pkl\", 'rb') as file:\n",
    "    vocabulary = pickle.load(file)\n",
    "\n",
    "with open(\"models/word2vecs/pwc3-win7-vec100-min5/word2vec.pkl\", 'rb') as file:\n",
    "    word2vec = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 100 * 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'a' in vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Returns the first not belonging token in the vocabulary\n",
    "\"\"\"\n",
    "def belong_to_vocabulary(tokens: list, vocabulary: list):\n",
    "    for token in tokens:\n",
    "        if not token in vocabulary:\n",
    "            return token\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(tokens: list, word2vec):\n",
    "    embedded_tokens = np.array([])\n",
    "    \n",
    "    for token in tokens:\n",
    "        embedded_tokens = np.append(embedded_tokens, word2vec.wv.get_vector(token))\n",
    "\n",
    "    return embedded_tokens.reshape(1, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "marvelous\n"
     ]
    }
   ],
   "source": [
    "# quick test\n",
    "\n",
    "print(belong_to_vocabulary(['a', 'story', 'the'], vocabulary))\n",
    "print(belong_to_vocabulary(['a', 'story', 'marvelous', 'the'], vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 108ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.67988485, 0.20432276, 0.07957686, ..., 0.12773414, 0.12160717,\n",
       "        0.6805879 ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.random.randn(1, input_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokens = ['a', 'story', 'about']\n",
    "test_tokens = ['the', 'main', 'character']\n",
    "test_tokens = ['my', 'feelings', 'were']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    }
   ],
   "source": [
    "not_belonging = belong_to_vocabulary(test_tokens, vocabulary)\n",
    "\n",
    "if not_belonging is None:\n",
    "    y_pred = model.predict(vectorize(test_tokens, word2vec))\n",
    "else:\n",
    "    print(\"ERROR: Word \\'{}\\' does not belong to the vocabulary\".format(not_belonging))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_word = vocabulary[np.argmax(y_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"data/reviews/neg/1_1.txt\")\n",
    "sample_review = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>positive</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I must admit, I was one of the skeptics who pr...</td>\n",
       "      <td>False</td>\n",
       "      <td>i must admit i was one of the skeptics who pre...</td>\n",
       "      <td>[i, must, admit, i, was, one, of, the, skeptic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Even though an animated film it really bored e...</td>\n",
       "      <td>False</td>\n",
       "      <td>even though an animated film it really bored e...</td>\n",
       "      <td>[even, though, an, animated, film, it, really,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bah. Another tired, desultory reworking of an ...</td>\n",
       "      <td>False</td>\n",
       "      <td>bah another tired desultory reworking of an ou...</td>\n",
       "      <td>[bah, another, tired, desultory, reworking, of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I had the opportunity to see this film debut a...</td>\n",
       "      <td>False</td>\n",
       "      <td>i had the opportunity to see this film debut a...</td>\n",
       "      <td>[i, had, the, opportunity, to, see, this, film...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Was lucky enough to be an extra in this great ...</td>\n",
       "      <td>False</td>\n",
       "      <td>was lucky enough to be an extra in this great ...</td>\n",
       "      <td>[was, lucky, enough, to, be, an, extra, in, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>This is a quirky movie that the Brits do so we...</td>\n",
       "      <td>False</td>\n",
       "      <td>this is a quirky movie that the brits do so we...</td>\n",
       "      <td>[this, is, a, quirky, movie, that, the, brits,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>For a long time it seemed like all the good Ca...</td>\n",
       "      <td>False</td>\n",
       "      <td>for a long time it seemed like all the good ca...</td>\n",
       "      <td>[for, a, long, time, it, seemed, like, all, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>This is a cartoon series where most of the act...</td>\n",
       "      <td>False</td>\n",
       "      <td>this is a cartoon series where most of the act...</td>\n",
       "      <td>[this, is, a, cartoon, series, where, most, of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>Sequel to \"The Kingdom\" is bloodier and even m...</td>\n",
       "      <td>False</td>\n",
       "      <td>sequel to the kingdom is bloodier and even mor...</td>\n",
       "      <td>[sequel, to, the, kingdom, is, bloodier, and, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>The orders fatal flaw-besides an asinine plot-...</td>\n",
       "      <td>False</td>\n",
       "      <td>the orders fatal flawbesides an asinine plotis...</td>\n",
       "      <td>[the, orders, fatal, flawbesides, an, asinine,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  positive  \\\n",
       "0     I must admit, I was one of the skeptics who pr...     False   \n",
       "1     Even though an animated film it really bored e...     False   \n",
       "2     Bah. Another tired, desultory reworking of an ...     False   \n",
       "3     I had the opportunity to see this film debut a...     False   \n",
       "4     Was lucky enough to be an extra in this great ...     False   \n",
       "...                                                 ...       ...   \n",
       "1495  This is a quirky movie that the Brits do so we...     False   \n",
       "1496  For a long time it seemed like all the good Ca...     False   \n",
       "1497  This is a cartoon series where most of the act...     False   \n",
       "1498  Sequel to \"The Kingdom\" is bloodier and even m...     False   \n",
       "1499  The orders fatal flaw-besides an asinine plot-...     False   \n",
       "\n",
       "                                             clean_text  \\\n",
       "0     i must admit i was one of the skeptics who pre...   \n",
       "1     even though an animated film it really bored e...   \n",
       "2     bah another tired desultory reworking of an ou...   \n",
       "3     i had the opportunity to see this film debut a...   \n",
       "4     was lucky enough to be an extra in this great ...   \n",
       "...                                                 ...   \n",
       "1495  this is a quirky movie that the brits do so we...   \n",
       "1496  for a long time it seemed like all the good ca...   \n",
       "1497  this is a cartoon series where most of the act...   \n",
       "1498  sequel to the kingdom is bloodier and even mor...   \n",
       "1499  the orders fatal flawbesides an asinine plotis...   \n",
       "\n",
       "                                              tokenized  \n",
       "0     [i, must, admit, i, was, one, of, the, skeptic...  \n",
       "1     [even, though, an, animated, film, it, really,...  \n",
       "2     [bah, another, tired, desultory, reworking, of...  \n",
       "3     [i, had, the, opportunity, to, see, this, film...  \n",
       "4     [was, lucky, enough, to, be, an, extra, in, th...  \n",
       "...                                                 ...  \n",
       "1495  [this, is, a, quirky, movie, that, the, brits,...  \n",
       "1496  [for, a, long, time, it, seemed, like, all, th...  \n",
       "1497  [this, is, a, cartoon, series, where, most, of...  \n",
       "1498  [sequel, to, the, kingdom, is, bloodier, and, ...  \n",
       "1499  [the, orders, fatal, flawbesides, an, asinine,...  \n",
       "\n",
       "[1500 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df = pd.read_csv(\"data/reviews_cleaned_sample.csv\", converters={'tokenized': pd.eval})\n",
    "reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_review = reviews_df.tokenized[0]\n",
    "type(sample_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_proposed_word = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_indices = np.argsort(y_pred).reshape(len(vocabulary))[-num_proposed_word:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a story about  in\n",
      "a story about  to\n",
      "a story about  and\n",
      "a story about  a\n",
      "a story about  the\n"
     ]
    }
   ],
   "source": [
    "for predicted_index in predicted_indices:\n",
    "    print(\"a story about \", vocabulary[predicted_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(config.PREVIOUS_WORDS_CONSIDERED, len(sample_review)):\n",
    "    tokens = sample_review[index-config.PREVIOUS_WORDS_CONSIDERED:index]\n",
    "    \n",
    "    not_belonging = belong_to_vocabulary(tokens, vocabulary)\n",
    "\n",
    "    if not_belonging is None:\n",
    "        y_pred = model.predict(vectorize(test_tokens, word2vec), verbose=0)\n",
    "\n",
    "        predicted_indices = np.argsort(y_pred).reshape(len(vocabulary))[-num_proposed_word:]\n",
    "\n",
    "        # for index in predicted_indices:\n",
    "        #     print(vocabulary[index])\n",
    "        # print()\n",
    "        if vocabulary[np.argmax(y_pred)] != \"the\":\n",
    "            print(tokens, vocabulary[np.argmax(y_pred)])\n",
    "            print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
